{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import copy\n",
    "from model.model import get_3Dlandmark_reg_model\n",
    "from data_load.pose_estim_dataset import load_data\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_data(['../Data_preparation/DatasetN2_3.csv'], model_type='M2', full_dataset=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigthed_mse_loss(predicted_pos, target_pos, visibility):\n",
    "    mse_loss = torch.mean(visibility.unsqueeze(2)*(predicted_pos - target_pos)**2)\n",
    "    return mse_loss\n",
    "\n",
    "criterion = weigthed_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n",
      "Pre-trained model loaded with versions/model1_M2_18_9.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, tloss: 0.2554798722267151, vloss: 0.248375, : 100%|██████████| 113/113 [00:00<00:00, 151.14it/s]\n",
      "Epoch: 2, tloss: 0.20888292789459229, vloss: 0.217625, Improvement found, counter reset to 0: 100%|██████████| 113/113 [00:00<00:00, 119.85it/s]\n",
      "Epoch: 3, tloss: 0.2654554545879364, vloss: 0.196167, Improvement found, counter reset to 0: 100%|██████████| 113/113 [00:00<00:00, 148.51it/s]\n",
      "Epoch: 4, tloss: 0.2909855246543884, vloss: 0.308972, No improvement in the last 1 epochs: 100%|██████████| 113/113 [00:00<00:00, 142.27it/s]\n",
      "Epoch: 5, tloss: 0.2634470760822296, vloss: 0.260773, No improvement in the last 2 epochs: 100%|██████████| 113/113 [00:00<00:00, 136.93it/s]\n",
      "Epoch: 6, tloss: 0.31587034463882446, vloss: 0.307754, No improvement in the last 3 epochs: 100%|██████████| 113/113 [00:00<00:00, 114.89it/s]\n",
      "Epoch: 7, tloss: 0.4155537188053131, vloss: 0.366240, No improvement in the last 4 epochs: 100%|██████████| 113/113 [00:00<00:00, 119.00it/s]\n",
      "Epoch: 8, tloss: 0.34979525208473206, vloss: 0.272894, No improvement in the last 5 epochs: 100%|██████████| 113/113 [00:01<00:00, 105.10it/s]\n",
      "Epoch: 9, tloss: 0.21950681507587433, vloss: 0.338592, No improvement in the last 6 epochs: 100%|██████████| 113/113 [00:00<00:00, 136.64it/s]\n",
      "Epoch: 10, tloss: 0.21404533088207245, vloss: 0.367366, No improvement in the last 7 epochs: 100%|██████████| 113/113 [00:00<00:00, 131.57it/s]\n",
      "Epoch: 11, tloss: 0.18828080594539642, vloss: 0.183156, Improvement found, counter reset to 0: 100%|██████████| 113/113 [00:01<00:00, 104.70it/s]\n",
      "Epoch: 12, tloss: 0.19212473928928375, vloss: 0.212537, No improvement in the last 1 epochs: 100%|██████████| 113/113 [00:00<00:00, 129.44it/s]\n",
      "Epoch: 13, tloss: 0.2776021659374237, vloss: 0.186425, No improvement in the last 2 epochs: 100%|██████████| 113/113 [00:01<00:00, 101.75it/s]\n",
      "Epoch: 14, tloss: 0.23522047698497772, vloss: 0.213927, No improvement in the last 3 epochs: 100%|██████████| 113/113 [00:00<00:00, 126.74it/s]\n",
      "Epoch: 15, tloss: 0.3115566670894623, vloss: 0.337618, No improvement in the last 4 epochs: 100%|██████████| 113/113 [00:01<00:00, 89.46it/s]\n",
      "Epoch: 16, tloss: 0.19299010932445526, vloss: 0.189748, No improvement in the last 5 epochs: 100%|██████████| 113/113 [00:01<00:00, 92.84it/s] \n",
      "Epoch: 17, tloss: 0.2596803903579712, vloss: 0.272207, No improvement in the last 6 epochs: 100%|██████████| 113/113 [00:01<00:00, 94.90it/s]\n",
      "Epoch: 18, tloss: 0.39680206775665283, vloss: 0.483933, No improvement in the last 7 epochs: 100%|██████████| 113/113 [00:01<00:00, 83.46it/s]\n",
      "Epoch: 19, tloss: 0.25186240673065186, vloss: 0.154039, Improvement found, counter reset to 0: 100%|██████████| 113/113 [00:01<00:00, 82.39it/s]\n",
      "Epoch: 20, tloss: 0.1896139234304428, vloss: 0.167268, No improvement in the last 1 epochs: 100%|██████████| 113/113 [00:02<00:00, 53.57it/s]\n",
      "Epoch: 21, tloss: 0.2857951819896698, vloss: 0.325980, No improvement in the last 2 epochs: 100%|██████████| 113/113 [00:01<00:00, 78.17it/s]\n",
      "Epoch: 22, tloss: 0.34478288888931274, vloss: 0.171603, No improvement in the last 3 epochs: 100%|██████████| 113/113 [00:01<00:00, 76.82it/s]\n",
      "Epoch: 23, tloss: 0.24818700551986694, vloss: 0.202104, No improvement in the last 4 epochs: 100%|██████████| 113/113 [00:01<00:00, 79.77it/s]\n",
      "Epoch: 24, tloss: 0.20402348041534424, vloss: 0.313960, No improvement in the last 5 epochs: 100%|██████████| 113/113 [00:01<00:00, 64.77it/s]\n",
      "Epoch: 25, tloss: 0.2167496681213379, vloss: 0.177066, No improvement in the last 6 epochs: 100%|██████████| 113/113 [00:01<00:00, 71.28it/s]\n",
      "Epoch: 26, tloss: 0.25058403611183167, vloss: 0.181033, No improvement in the last 7 epochs: 100%|██████████| 113/113 [00:01<00:00, 84.50it/s]\n",
      "Epoch: 27, tloss: 0.21545305848121643, vloss: 0.202811, No improvement in the last 8 epochs: 100%|██████████| 113/113 [00:01<00:00, 66.53it/s]\n",
      "Epoch: 28, tloss: 0.18003115057945251, vloss: 0.185500, No improvement in the last 9 epochs: 100%|██████████| 113/113 [00:01<00:00, 87.29it/s]\n",
      "Epoch: 29, tloss: 0.3920021057128906, vloss: 0.560935, Early stopping triggered after 10 epochs.: 100%|██████████| 113/113 [00:01<00:00, 72.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using {device} device.')\n",
    "\n",
    "n_landmarks = 9\n",
    "\n",
    "model = get_3Dlandmark_reg_model(n_landmarks=n_landmarks, is_train=True, training_path='versions/model1_M2_18_9.pt', device=device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "epoch = 0\n",
    "num_epochs = 150\n",
    "done = False\n",
    "es = EarlyStopping(patience=10)\n",
    "\n",
    "while epoch < num_epochs and not done:\n",
    "    epoch += 1\n",
    "    model.train()\n",
    "    \n",
    "    steps = list(enumerate(train_loader))\n",
    "    pbar = tqdm.tqdm(steps)\n",
    "\n",
    "    for batch_index, (input, target, visibility) in pbar:\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        visibility = visibility.to(device)\n",
    "\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = criterion(output, target, visibility)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss, current = loss.item(), (batch_index+1)*len(input)\n",
    "\n",
    "        if batch_index == len(steps) - 1:\n",
    "            model.eval()\n",
    "            output = model(input)\n",
    "            vloss = criterion(output, target, visibility)\n",
    "            if es(model, vloss):\n",
    "                done = True\n",
    "            pbar.set_description(\n",
    "                f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:>7f}, {es.status}\"\n",
    "            )\n",
    "        else:\n",
    "            pbar.set_description(f\"Epoch: {epoch}, tloss {loss:}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model loaded with versions/model1_M2_18_9.pt\n"
     ]
    }
   ],
   "source": [
    "#n_landmarks = 9\n",
    "#device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "model = get_3Dlandmark_reg_model(n_landmarks=n_landmarks, is_train=True, training_path='versions/model1_M2_18_9.pt', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8795979086841855\n",
      "Average error: [0.41147593 0.3897819  0.8167491 ]\n"
     ]
    }
   ],
   "source": [
    "val_loader = load_data(['../Data_preparation/DatasetN3_3.csv'], model_type='M2', full_dataset=True)\n",
    "\n",
    "def error_analysis(target, output, visibility):\n",
    "    error = visibility.unsqueeze(2)*torch.abs(target - output)\n",
    "    error = torch.mean(error, axis=0)\n",
    "    error = torch.mean(error, axis=0)\n",
    "\n",
    "    return error\n",
    "\n",
    "# Evaluation on validation set\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "error_vect = []\n",
    "with torch.no_grad():\n",
    "    for input, target, visibility in val_loader:\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        visibility = visibility.to(device)\n",
    "        output = model(input)\n",
    "        error_vect.append(error_analysis(target, output, visibility))\n",
    "        current = criterion(output, target, visibility).item()\n",
    "        val_loss += current\n",
    "\n",
    "print(f'Validation Loss: {val_loss / len(val_loader)}')\n",
    "error = np.mean(np.array(error_vect), axis=0)\n",
    "print(f'Average error: {error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: {20: {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}, 19: {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}, 18: {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}, 17: {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}, 16: {'mean': 0, 'error': array([ 3.7787595,  1.301108 , 11.384624 ], dtype=float32), 'count': 12, 'v_count': 12.0}, 15: {'mean': 0, 'error': array([ 55.84934,  46.60326, 144.23085], dtype=float32), 'count': 166, 'v_count': 166.0}, 14: {'mean': 0, 'error': array([ 66.450195,  87.52027 , 176.31114 ], dtype=float32), 'count': 206, 'v_count': 206.0}, 13: {'mean': 0, 'error': array([ 84.255974, 101.34584 , 179.60997 ], dtype=float32), 'count': 206, 'v_count': 206.0}, 12: {'mean': 0, 'error': array([ 94.18993, 119.08504, 165.84067], dtype=float32), 'count': 204, 'v_count': 204.0}, 11: {'mean': 0, 'error': array([111.818016,  96.846466, 178.46942 ], dtype=float32), 'count': 216, 'v_count': 211.3333333333332}, 10: {'mean': 0, 'error': array([ 94.346954,  70.46107 , 149.6185  ], dtype=float32), 'count': 203, 'v_count': 197.66666666666654}, 9: {'mean': 0, 'error': array([ 91.8965  ,  69.362495, 180.76445 ], dtype=float32), 'count': 207, 'v_count': 196.3333333333331}, 8: {'mean': 0, 'error': array([ 78.07694 ,  60.086216, 153.92082 ], dtype=float32), 'count': 199, 'v_count': 187.99999999999977}, 7: {'mean': 0, 'error': array([ 69.09153,  54.75418, 140.5188 ], dtype=float32), 'count': 171, 'v_count': 161.88888888888866}, 6: {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}, 5: {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}, 4: {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}}\n",
      "Range: 200-210 cm, Mean error: (0)cm --> number of samples: 0, visibility: 0\n",
      "Range: 190-200 cm, Mean error: (0)cm --> number of samples: 0, visibility: 0\n",
      "Range: 180-190 cm, Mean error: (0)cm --> number of samples: 0, visibility: 0\n",
      "Range: 170-180 cm, Mean error: (0)cm --> number of samples: 0, visibility: 0\n",
      "Range: 160-170 cm, Mean error: ([0.31 0.11 0.95])cm --> number of samples: 12, visibility: 1.0\n",
      "Range: 150-160 cm, Mean error: ([0.34 0.28 0.87])cm --> number of samples: 166, visibility: 1.0\n",
      "Range: 140-150 cm, Mean error: ([0.32 0.42 0.86])cm --> number of samples: 206, visibility: 1.0\n",
      "Range: 130-140 cm, Mean error: ([0.41 0.49 0.87])cm --> number of samples: 206, visibility: 1.0\n",
      "Range: 120-130 cm, Mean error: ([0.46 0.58 0.81])cm --> number of samples: 204, visibility: 1.0\n",
      "Range: 110-120 cm, Mean error: ([0.52 0.45 0.83])cm --> number of samples: 216, visibility: 0.98\n",
      "Range: 100-110 cm, Mean error: ([0.46 0.35 0.74])cm --> number of samples: 203, visibility: 0.97\n",
      "Range: 90-100 cm, Mean error: ([0.44 0.34 0.87])cm --> number of samples: 207, visibility: 0.95\n",
      "Range: 80-90 cm, Mean error: ([0.39 0.3  0.77])cm --> number of samples: 199, visibility: 0.94\n",
      "Range: 70-80 cm, Mean error: ([0.4  0.32 0.82])cm --> number of samples: 171, visibility: 0.95\n",
      "Range: 60-70 cm, Mean error: (0)cm --> number of samples: 0, visibility: 0\n",
      "Range: 50-60 cm, Mean error: (0)cm --> number of samples: 0, visibility: 0\n",
      "Range: 40-50 cm, Mean error: (0)cm --> number of samples: 0, visibility: 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Prediction on test set\n",
    "model.eval()\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "in_values = []\n",
    "dict = {}\n",
    "for w in range(20, 3, -1):\n",
    "    dict[w] = {'mean': 0, 'error': 0, 'count': 0, 'v_count': 0}\n",
    "with torch.no_grad():\n",
    "    for input, target, visibility in val_loader:\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        visibility = visibility.to(device)\n",
    "        output = model(input)\n",
    "\n",
    "        input = input.cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        visibility = visibility.cpu().numpy()\n",
    "        output = output.cpu().numpy()\n",
    "\n",
    "        for i in range(output.shape[0]):\n",
    "            in_frame = target[i,np.where(visibility[i] == 1),:].squeeze(0)\n",
    "            in_frame_out = output[i,np.where(visibility[i] == 1),:].squeeze(0)\n",
    "            v_range = math.floor(np.abs(np.mean(in_frame[:,-1], axis=0))/10)\n",
    "            if v_range in dict.keys():\n",
    "                dict[v_range]['error'] += np.mean(np.abs(in_frame - in_frame_out), axis=0)\n",
    "                dict[v_range]['count'] += 1\n",
    "                dict[v_range]['v_count'] += np.sum(visibility[i,:])/visibility.shape[1]\n",
    "                \n",
    "        in_values.append(input)\n",
    "        predictions.append(output)\n",
    "        ground_truth.append(target)\n",
    "print(f'Prediction: {dict}')\n",
    "for k in dict.keys():\n",
    "    if dict[k]['count'] != 0:\n",
    "        dict[k]['mean'] = np.round(dict[k]['error']/dict[k]['count'],2)\n",
    "        dict[k]['v_count'] = np.round(dict[k]['v_count']/dict[k]['count'],2)\n",
    "    print(f'Range: {k*10}-{(k+1)*10} cm, Mean error: ({dict[k][\"mean\"]})cm --> number of samples: {dict[k][\"count\"]}, visibility: {dict[k][\"v_count\"]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'versions/model3_M3_18_9.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from CAD_transf import get_points\n",
    "ground_truth = np.array(get_points())*100\n",
    "ground_truth[:,2] -= ground_truth[0,2]\n",
    "np.savetxt('CPD/data/ground_truth.txt', ground_truth, delimiter=' ')\n",
    "\n",
    "data = pd.read_csv('../Data_preparation/DatasetN2_3.csv')\n",
    "points3D = []\n",
    "points2D = []\n",
    "for i in range(9):\n",
    "    points2D.append(f'LDM{i}x')\n",
    "    points2D.append(f'LDM{i}y')\n",
    "    points3D.append(f'x{i}')\n",
    "    points3D.append(f'y{i}')\n",
    "    points3D.append(f'z{i}')\n",
    "\n",
    "points2D = np.array(data[points2D].values[0]).reshape(1,18)/512\n",
    "points3D = np.array(data[points3D].values[0]).reshape(1,9,3)\n",
    "\n",
    "print('Image orientation: ', (data['roll'].values[0], data['pitch'].values[0], data['yaw'].values[0]))\n",
    "print('Camera position: ', (data['x'].values[0], data['y'].values[0], data['z'].values[0]))\n",
    "\n",
    "#print(points2D)\n",
    "print(points3D)\n",
    "\n",
    "out = model(torch.tensor(points2D, dtype=torch.float32).to(device))\n",
    "out = out.squeeze(0).detach().numpy()\n",
    "print(out)\n",
    "np.savetxt('CPD/data/prediction.txt', out, delimiter=' ') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'versions/model1_18_9.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(X,Y,Z) from perspective matrix and Z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
